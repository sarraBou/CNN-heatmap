{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_trick.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj84wO9fKUQp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # cv2.imshow does not work on Google Colab notebooks, --> use cv2_imshow instead"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOXvca0pFYdA"
      },
      "source": [
        "# loading settings\n",
        "model_string = \"resnet50\"  # inceptionv3, resnet50, vgg16\n",
        "dataset_string = \"imagenet\"  # imagenet\n",
        "\n",
        "# other settings\n",
        "heatmap_intensity = 0.5\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# data set\n",
        "#path_to_dataset = '/content/gdrive/My Drive/What are CNNs looking at/files/New Masks Dataset/'\n",
        "#path_to_dataset = '/content/gdrive/My Drive/Kaggle/files/Face Mask Dataset'\n",
        "path_to_dataset = '/content/gdrive/.shortcut-targets-by-id/1wI0fw-edJDu1RgH2Ldk3n4VBJ4m4EJuv/combined'\n",
        "other_path = \"/content/gdrive/My Drive/What are CNNs looking at/New Masks Dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFDU-LCmmv7n"
      },
      "source": [
        "def gradCAM(orig, model, model_string, DIM, HM_DIM, last_layer, classes, intensity=0.5, res=250):\n",
        "\n",
        "    if model_string == \"inceptionv3\":\n",
        "        from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "\n",
        "    elif model_string == \"resnet50\":\n",
        "        from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "    elif model_string == \"vgg16\":\n",
        "        from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "\n",
        "    else:  # use InceptionV3 and imagenet as default\n",
        "        from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "\n",
        "\n",
        "    img = image.load_img(orig, target_size=(DIM, DIM))\n",
        "\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    preds = model.predict(x)\n",
        "    for pred_it, label_it in zip(preds[0], classes):\n",
        "      print(label_it, \": \", pred_it)\n",
        "    print(\"preds\")\n",
        "    print(preds)\n",
        "    prob = np.max(preds[0])\n",
        "    index = list(preds[0]).index(prob)\n",
        "    label = classes[index]\n",
        "    label = \"{}: {:.2f}%\".format(label, prob * 100)\n",
        "    print(\"[INFO] {}\".format(label))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer = model.get_layer(last_layer)\n",
        "        iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output]) # run model and achive certain output 'last_conv_layer.output'\n",
        "        model_out, last_conv_layer = iterate(x)\n",
        "        class_out = model_out[:, np.argmax(model_out[0])]\n",
        "        grads = tape.gradient(class_out, last_conv_layer) # class out: take derivative; last_conv_layer: variable to derive from\n",
        "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "    heatmap = heatmap.reshape((HM_DIM, HM_DIM))\n",
        "\n",
        "    img_original = cv2.imread(orig)\n",
        "    heatmap = cv2.resize(heatmap, (img_original.shape[1], img_original.shape[0]))\n",
        "    # plt.matshow(heatmap)\n",
        "    # plt.show()\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "    # plt.matshow(heatmap)\n",
        "    # plt.show()\n",
        "    img_heatmap = heatmap * intensity + img_original\n",
        "\n",
        "    cv2_imshow(img_heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPfYNA_UFdFu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b1ed43-fb73-4bfb-9fbc-1b817ccc5723"
      },
      "source": [
        "# model dependent imports, weight loading and model dependent parameter setting\n",
        "K.clear_session()\n",
        "if model_string == \"inceptionv3\":\n",
        "    from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "    from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "    Model = InceptionV3\n",
        "    if dataset_string == \"imagenet\":\n",
        "        model = InceptionV3(weights='imagenet')\n",
        "    target_input_dimension = 299\n",
        "    heatmap_dimension = 8\n",
        "    last_layer_name = 'conv2d_93'\n",
        "elif model_string == \"resnet50\":\n",
        "    from tensorflow.keras.applications import ResNet50\n",
        "    from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "    Model = ResNet50\n",
        "    if dataset_string == \"imagenet\":\n",
        "        model = ResNet50(weights=\"imagenet\")\n",
        "    target_input_dimension = 224\n",
        "    heatmap_dimension = 7\n",
        "    last_layer_name = 'conv5_block3_3_conv'\n",
        "elif model_string == \"vgg16\":\n",
        "    from tensorflow.keras.applications import VGG16\n",
        "    from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "    Model = VGG16\n",
        "    if dataset_string == \"imagenet\":\n",
        "        model = VGG16(weights=\"imagenet\")\n",
        "    target_input_dimension = 224\n",
        "    heatmap_dimension = 14\n",
        "    last_layer_name = 'block5_conv3'\n",
        "else:  # use InceptionV3 and imagenet as default\n",
        "    from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "    from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "    if dataset_string == \"imagenet\":\n",
        "        model = InceptionV3(weights='imagenet')\n",
        "    target_input_dimension = 299\n",
        "    heatmap_dimension = 8\n",
        "    last_layer_name = 'conv2d_93'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XcUkUbaPyWW",
        "outputId": "2cdf2bb1-68f6-4622-fda8-0893ac8d00a4"
      },
      "source": [
        "# mount google drive to access database\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jm7fLHaNQ4f"
      },
      "source": [
        "class_names=['Mask', 'Non Mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0zHcjksPpSu"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/\n",
        "%ll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wX8SSQ2G09_"
      },
      "source": [
        "%cd /content/gdrive/MyDrive\n",
        "%cd /content/gdrive/.shortcut-targets-by-id/1CYXqSpprxFgIFpiRfRSoR_KL7ZIOXtOA/combined\n",
        "#sos attempt path\n",
        "path_to_dataset= '/content/gdrive/.shortcut-targets-by-id/1CYXqSpprxFgIFpiRfRSoR_KL7ZIOXtOA/combined/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FWsEEMzyE8S"
      },
      "source": [
        "# import database\n",
        "\n",
        "train_dir = os.path.join(path_to_dataset, 'Train')\n",
        "validation_dir = os.path.join(path_to_dataset, 'Validation')\n",
        "test_dir = os.path.join(path_to_dataset, 'Test')\n",
        "BATCH_SIZE = 64\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)\n",
        "validation_dataset = image_dataset_from_directory(validation_dir,\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)\n",
        "test_dataset = image_dataset_from_directory(test_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onwQ06lXNAeU"
      },
      "source": [
        "# Sarra\n",
        "#%cd /content/gdrive/.shortcut-targets-by-id/1D594PlXLC7S5YLnKD2s09vbezmGes8H6/What are CNNs looking at\n",
        "#sos\n",
        "%cd /content/gdrive/.shortcut-targets-by-id/1D594PlXLC7S5YLnKD2s09vbezmGes8H6/What are CNNs looking at\n",
        "# Jan-Lukas\n",
        "#%cd /content/gdrive/My Drive/What are CNNs looking at\n",
        "\n",
        "model_new = tf.keras.models.load_model('saved_model/resnet50trained_wrongmask')\n",
        "model_new.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99WWBgBhOPqN"
      },
      "source": [
        "%cd /content/gdrive/.shortcut-targets-by-id/1D594PlXLC7S5YLnKD2s09vbezmGes8H6/What are CNNs looking at\n",
        "images = [ 'JLM_5.jpg', 'JLM_6.jpg', 'JLM_7.jpg', 'JLM_2a.jpg', 'JLM_3a.jpg', 'JLM_1a.jpg', 'maskWrong.PNG','nomask.PNG',\n",
        "          'abin_halfmask.jpg', 'maskdown.PNG', 'maskdown2.PNG','maskdown3.PNG','maskchin.PNG','maskchin1.PNG']\n",
        "DIM = 224\n",
        "for orig in images:\n",
        "  gradCAM(orig, model_new, model_string, target_input_dimension, heatmap_dimension,'tf.identity',class_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpu5lt-zMwAj"
      },
      "source": [
        "%cd /content/gdrive/.shortcut-targets-by-id/1D594PlXLC7S5YLnKD2s09vbezmGes8H6/What are CNNs looking at\n",
        "images = ['m'askWrong.PNG,'nomask.PNG','abin_halfmask.jpg', 'maskdown.PNG', 'maskdown2.PNG','maskdown3.PNG','maskchin.PNG','maskchin1.PNG']\n",
        "\n",
        "DIM = 224\n",
        "for orig in images:\n",
        "  gradCAM(orig, model, model_string, target_input_dimension, heatmap_dimension,'tf.identity',class_names)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}