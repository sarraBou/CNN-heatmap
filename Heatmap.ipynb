{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj84wO9fKUQp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # cv2.imshow does not work on Google Colab notebooks, --> use cv2_imshow instead"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjO4IRSM8y71"
      },
      "source": [
        "def gradCAM(orig, model, model_string, DIM, HM_DIM, last_layer, intensity=0.5, res=250):\n",
        "\n",
        "    if model_string == \"inceptionv3\":\n",
        "        from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "\n",
        "    elif model_string == \"resnet50\":\n",
        "        from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "    elif model_string == \"vgg16\":\n",
        "        from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "\n",
        "    else:  # use InceptionV3 and imagenet as default\n",
        "        from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "\n",
        "\n",
        "    img = image.load_img(orig, target_size=(DIM, DIM))\n",
        "\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    preds = model.predict(x)\n",
        "    decoded = imagenet_utils.decode_predictions(preds)\n",
        "    (imagenetID, label, prob) = decoded[0][0]\n",
        "    label = \"{}: {:.2f}%\".format(label, prob * 100)\n",
        "    print(\"[INFO] {}\".format(label))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer = model.get_layer(last_layer)\n",
        "        iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output]) # run model and achive certain output 'last_conv_layer.output'\n",
        "        model_out, last_conv_layer = iterate(x)\n",
        "        class_out = model_out[:, np.argmax(model_out[0])]\n",
        "        grads = tape.gradient(class_out, last_conv_layer) # class out: take derivative; last_conv_layer: variable to derive from\n",
        "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "    heatmap = heatmap.reshape((HM_DIM, HM_DIM))\n",
        "\n",
        "    img_original = cv2.imread(orig)\n",
        "    heatmap = cv2.resize(heatmap, (img_original.shape[1], img_original.shape[0]))\n",
        "    # plt.matshow(heatmap)\n",
        "    # plt.show()\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "    # plt.matshow(heatmap)\n",
        "    # plt.show()\n",
        "    img_heatmap = heatmap * intensity + img_original\n",
        "\n",
        "    cv2_imshow(img_heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWAVhEnz9Xx4"
      },
      "source": [
        "# loading settings\n",
        "model_string = \"inceptionv3\"  # inceptionv3, resnet50, vgg16\n",
        "dataset_string = \"imagenet\"  # imagenet\n",
        "\n",
        "# other settings\n",
        "heatmap_intensity = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgtghB-L9gZe"
      },
      "source": [
        "# model dependent imports, weight loading and model dependent parameter setting\n",
        "K.clear_session()\n",
        "if model_string == \"inceptionv3\":\n",
        "    from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "    Model = InceptionV3\n",
        "    if dataset_string == \"imagenet\":\n",
        "        model = InceptionV3(weights='imagenet')\n",
        "    target_input_dimension = 299\n",
        "    heatmap_dimension = 8\n",
        "    last_layer_name = 'conv2d_93'\n",
        "elif model_string == \"resnet50\":\n",
        "    from tensorflow.keras.applications import ResNet50\n",
        "    Model = ResNet50\n",
        "    if dataset_string == \"imagenet\":\n",
        "        model = ResNet50(weights=\"imagenet\")\n",
        "    target_input_dimension = 224\n",
        "    heatmap_dimension = 7\n",
        "    last_layer_name = 'conv5_block3_3_conv'\n",
        "elif model_string == \"vgg16\":\n",
        "    from tensorflow.keras.applications import VGG16\n",
        "    Model = VGG16\n",
        "    if dataset_string == \"imagenet\":\n",
        "        model = VGG16(weights=\"imagenet\")\n",
        "    target_input_dimension = 224\n",
        "    heatmap_dimension = 14\n",
        "    last_layer_name = 'block5_conv3'\n",
        "else:  # use InceptionV3 and imagenet as default\n",
        "    from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "    if dataset_string == \"imagenet\":\n",
        "        model = InceptionV3(weights='imagenet')\n",
        "    target_input_dimension = 299\n",
        "    heatmap_dimension = 8\n",
        "    last_layer_name = 'conv2d_93'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hscw77MsVn2k"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5F1ZZ8lVuAU"
      },
      "source": [
        "image_url = \"https://indiasendangered.com/wp-content/uploads/2011/09/elephant.jpg\"\n",
        "# image_url = \"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12234558/Chinook-On-White-03.jpg\"\n",
        "# image_url = \"https://icatcare.org/app/uploads/2018/07/Thinking-of-getting-a-cat.png\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMPw--cy7RaG"
      },
      "source": [
        "!wget $image_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1EoIsAr84cl"
      },
      "source": [
        "image_filename = image_url.split('/')[-1]\n",
        "gradCAM(image_filename, model, model_string, target_input_dimension, heatmap_dimension, last_layer_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D_5l8AHE_h9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
