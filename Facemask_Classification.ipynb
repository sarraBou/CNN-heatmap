{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facemask-Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj84wO9fKUQp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # cv2.imshow does not work on Google Colab notebooks, --> use cv2_imshow instead"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWAVhEnz9Xx4"
      },
      "source": [
        "# loading settings\n",
        "model_string = \"resnet50\"  # inceptionv3, resnet50, vgg16\n",
        "dataset_string = \"imagenet\"  # imagenet\n",
        "\n",
        "\n",
        "# other settings\n",
        "heatmap_intensity = 0.5\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "\n",
        "# data set\n",
        "\n",
        "#default one, labels via folder structure, 1006 images (600 for training), 214 MB total\n",
        "#path_to_dataset = '/content/gdrive/My Drive/What are CNNs looking at/New Masks Dataset/' \n",
        "\n",
        "#augmented ??\n",
        "#path_to_dataset = '/content/gdrive/My Drive/What are CNNs looking at/files/Face Mask Dataset/' \n",
        "\n",
        "#multiple masks per image, bounding boxes, xml-labels, 853 images, 399 MB\n",
        "#path_to_dataset = '/content/gdrive/My Drive/What are CNNs looking at/files/Face_Mask_Detection/images/' \n",
        "\n",
        "# former Face Mask Detection Dataset\n",
        "# multiple masks per image, bounding boxes, csv/json-labels, 4326 images, <3 GB\n",
        "# path_to_dataset = '/content/gdrive/My Drive/What are CNNs looking at/files/Multi Face Masks per Image clean/images' \n",
        "\n",
        "# one mask per image, labels via folder structure, 12k files (10k for training), 329 MB total\n",
        "path_to_dataset = '/content/gdrive/My Drive/What are CNNs looking at/files/12k Face Mask Dataset/' \n",
        "\n",
        "# todo: description\n",
        "#path_to_dataset = '/content/gdrive/My Drive/Kaggle/files/New_Masks_Dataset'\n",
        "\n",
        "# deprecated\n",
        "# multiple masks per image, bounding boxes, csv/json-labels, 6024 images (4326 usable because of missing labels), 3 GB\n",
        "#path_to_dataset = '/content/gdrive/MyDrive/What are CNNs looking at/files/Face Mask Detection Dataset/Medical mask/Medical mask/Medical Mask/images' \n",
        "\n",
        "\n",
        "\n",
        "other_path = \"/content/gdrive/My Drive/What are CNNs looking at/New Masks Dataset/\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgtghB-L9gZe"
      },
      "source": [
        "# model dependent imports, weight loading and model dependent parameter setting\n",
        "K.clear_session()\n",
        "if model_string == \"inceptionv3\":\n",
        "    from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "    from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "    Model = InceptionV3\n",
        "    if dataset_string == \"imagenet\":\n",
        "        model = InceptionV3(weights='imagenet')\n",
        "    target_input_dimension = 299\n",
        "    heatmap_dimension = 8\n",
        "    last_layer_name = 'conv2d_93'\n",
        "elif model_string == \"resnet50\":\n",
        "    from tensorflow.keras.applications import ResNet50\n",
        "    from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "    Model = ResNet50\n",
        "    if dataset_string == \"imagenet\":\n",
        "        #model = ResNet50(weights=\"imagenet\")\n",
        "        model = ResNet50()\n",
        "    target_input_dimension = 224\n",
        "    heatmap_dimension = 7\n",
        "    last_layer_name = 'conv5_block3_3_conv'\n",
        "elif model_string == \"vgg16\":\n",
        "    from tensorflow.keras.applications import VGG16\n",
        "    from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "    Model = VGG16\n",
        "    if dataset_string == \"imagenet\":\n",
        "        model = VGG16(weights=\"imagenet\")\n",
        "    target_input_dimension = 224\n",
        "    heatmap_dimension = 14\n",
        "    last_layer_name = 'block5_conv3'\n",
        "else:  # use InceptionV3 and imagenet as default\n",
        "    from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "    from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "    if dataset_string == \"imagenet\":\n",
        "        model = InceptionV3(weights='imagenet')\n",
        "    target_input_dimension = 299\n",
        "    heatmap_dimension = 8\n",
        "    last_layer_name = 'conv2d_93'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjO4IRSM8y71"
      },
      "source": [
        "def gradCAM(orig, model, model_string, DIM, HM_DIM, last_layer, classes, intensity=0.5, res=250):\n",
        "    img = image.load_img(orig, target_size=(DIM, DIM))\n",
        "\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    preds = model.predict(x)\n",
        "    for pred_it, label_it in zip(preds[0], classes):\n",
        "      print(label_it, \": \", pred_it)\n",
        "    print(\"preds\")\n",
        "    print(preds)\n",
        "    prob = np.max(preds[0])\n",
        "    index = list(preds[0]).index(prob)\n",
        "    label = classes[index]\n",
        "    label = \"{}: {:.2f}%\".format(label, prob * 100)\n",
        "    print(\"[INFO] {}\".format(label))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer = model.get_layer(last_layer)\n",
        "        iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output]) # run model and achive certain output 'last_conv_layer.output'\n",
        "        model_out, last_conv_layer = iterate(x)\n",
        "        class_out = model_out[:, np.argmax(model_out[0])]\n",
        "        grads = tape.gradient(class_out, last_conv_layer) # class out: take derivative; last_conv_layer: variable to derive from\n",
        "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "    heatmap = heatmap.reshape((HM_DIM, HM_DIM))\n",
        "\n",
        "    img_original = cv2.imread(orig)\n",
        "    heatmap = cv2.resize(heatmap, (img_original.shape[1], img_original.shape[0]))\n",
        "    # plt.matshow(heatmap)\n",
        "    # plt.show()\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "    # plt.matshow(heatmap)\n",
        "    # plt.show()\n",
        "    img_heatmap = heatmap * intensity + img_original\n",
        "\n",
        "    #cv2_imshow(img_heatmap)\n",
        "    return img_heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vIsMvCz7-Yt"
      },
      "source": [
        "# mount google drive to access database\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Yn5rtE8EKs"
      },
      "source": [
        "%cd $path_to_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1iLhegO6dg1"
      },
      "source": [
        "# import database - labels from file system\n",
        "\n",
        "train_dir = os.path.join(path_to_dataset, 'Train')\n",
        "validation_dir = os.path.join(path_to_dataset, 'Validation')\n",
        "test_dir = os.path.join(path_to_dataset, 'Test')\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)\n",
        "validation_dataset = image_dataset_from_directory(validation_dir,\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)\n",
        "test_dataset = image_dataset_from_directory(test_dir,\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI6auN8-Jxos"
      },
      "source": [
        "# import database - labels from file system - no validation data\n",
        "\n",
        "train_dir = os.path.join(path_to_dataset, 'Train')\n",
        "test_dir = os.path.join(path_to_dataset, 'Test')\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)\n",
        "test_dataset = image_dataset_from_directory(test_dir,\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)\n",
        "validation_dataset = test_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuw0MDlUi6IL"
      },
      "source": [
        "class_names = train_dataset.class_names\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc0I-GgHk9ZQ"
      },
      "source": [
        "# data augmntation \n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'), # horizontal_and_vertical, horizontal\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcPfbvTaN8VO"
      },
      "source": [
        "# observe train_dataset and image_dataset_from_directory\n",
        "print(type(train_dataset)) #tensorflow.python.data.ops.dataset_ops.BatchDataset\n",
        "print(train_dataset.class_names)\n",
        "#print(np.shape(train_dataset.images)) #(batch_size, image_size[0], image_size[1], num_channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL-rbCDGznYO"
      },
      "source": [
        "# define list of example images (e.g. for heatmap)\n",
        "\n",
        "if path_to_dataset == '/content/gdrive/My Drive/What are CNNs looking at/New Masks Dataset/':\n",
        "  image_dir_mask = 'Test/Mask'\n",
        "  image_dir_no_maks = 'Test/Non Mask'\n",
        "  image_names_mask = ['2070.jpg', '2190.png', '2222.png', '2268.png']\n",
        "  image_names_no_maks = ['real_01033.jpg', 'real_01057.jpg', 'real_01061.jpg', 'real_01081.jpg']\n",
        "\n",
        "elif path_to_dataset == '/content/gdrive/My Drive/What are CNNs looking at/files/12k Face Mask Dataset/':\n",
        "  image_dir_mask = 'Test/WithMask'\n",
        "  image_dir_no_maks = 'Test/WithoutMask'\n",
        "  image_names_mask = ['1175.png', '1362.png', '1404.png', '1439.png', '190.png']\n",
        "  image_names_no_maks = ['1.png', '1407.png', '2246.png', '2871.png', '3574.png']\n",
        "\n",
        "else:\n",
        "  image_dir_mask = ''\n",
        "  image_dir_no_maks = ''\n",
        "  image_names_mask = []\n",
        "  image_names_no_maks = []\n",
        "  print(\"Warning! No sample images prepared!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfpLviH2tV7Q"
      },
      "source": [
        "# define list of example images from other database (e.g. for heatmap)\n",
        "\n",
        "if other_path == '/content/gdrive/My Drive/What are CNNs looking at/New Masks Dataset/':\n",
        "  image_dir_mask2 = 'Test/Mask'\n",
        "  image_dir_no_maks2 = 'Test/Non Mask'\n",
        "  image_names_mask2 = ['2070.jpg', '2190.png', '2222.png', '2268.png']\n",
        "  image_names_no_maks2 = ['real_01033.jpg', 'real_01057.jpg', 'real_01061.jpg', 'real_01081.jpg']\n",
        "\n",
        "elif other_path == '/content/gdrive/My Drive/What are CNNs looking at/files/12k Face Mask Dataset/':\n",
        "  image_dir_mask2 = 'Test/WithMask'\n",
        "  image_dir_no_maks2 = 'Test/WithoutMask'\n",
        "  image_names_mask2 = ['1175.png', '1362.png', '1404.png', '1439.png', '190.png']\n",
        "  image_names_no_maks2 = ['1.png', '1407.png', '2246.png', '2871.png', '3574.png']\n",
        "\n",
        "else:\n",
        "  image_dir_mask2 = ''\n",
        "  image_dir_no_maks2 = ''\n",
        "  image_names_mask2 = []\n",
        "  image_names_no_maks2 = []\n",
        "  print(\"Warning! No sample images prepared!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGzQMnZ8atot"
      },
      "source": [
        "# creating the model\n",
        "\n",
        "# currently ResNet50 is hard coded\n",
        "K.clear_session()\n",
        "\n",
        "# load ResNet50 without dense layers\n",
        "base_model = ResNet50(input_shape=(target_input_dimension, \n",
        "                               target_input_dimension, \n",
        "                               3), \n",
        "                  include_top=False, \n",
        "                  weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "# create 2 dense layers\n",
        "pooling_layer_2d = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(2, activation='softmax')  # 2 output classes\n",
        "# with 2 output neurons there is a reshaping error\n",
        "# using 1 output neuron works but this is less general\n",
        "\n",
        "# create new model (add dense layers to convolutional model 'base_model')\n",
        "inputs = tf.keras.Input(shape=(target_input_dimension, \n",
        "                               target_input_dimension, \n",
        "                               3))\n",
        "x = preprocess_input(inputs)\n",
        "#x = data_augmentation(x)\n",
        "x = base_model(x, training=False)  # Why training=False?\n",
        "x = tf.identity(x) # needed to be able to obtain heatmap\n",
        "x = pooling_layer_2d(x)\n",
        "outputs = prediction_layer(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "#              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "#              metrics=['accuracy'])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "# using from_logits=False because we use a softmax activation in the last layer\n",
        "# which provices a non-logit output in the range [0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hscw77MsVn2k"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIWZY92Hl0Rm"
      },
      "source": [
        "# bench marking\n",
        "loss0, accuracy0 = model.evaluate(validation_dataset)\n",
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEt8DHqioi_S"
      },
      "source": [
        "# heatmap bench mark\n",
        "\n",
        "downsize_factor = 1 # >=1\n",
        "\n",
        "for imagename in image_names_mask:\n",
        "  heatmap = gradCAM(image_dir_mask+'/'+imagename, model, model_string, target_input_dimension, heatmap_dimension, 'tf.identity',class_names)\n",
        "  heatmap = cv2.resize(heatmap, (int(heatmap.shape[1]/downsize_factor), int(heatmap.shape[0]/downsize_factor)))\n",
        "  cv2_imshow(heatmap)\n",
        "\n",
        "for imagename in image_names_no_maks:\n",
        "  heatmap = gradCAM(image_dir_no_maks+'/'+imagename, model, model_string, target_input_dimension, heatmap_dimension, 'tf.identity', class_names)\n",
        "  heatmap = cv2.resize(heatmap, (int(heatmap.shape[1]/downsize_factor), int(heatmap.shape[0]/downsize_factor)))\n",
        "  cv2_imshow(heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBZZbuRql35w"
      },
      "source": [
        "# retrain\n",
        "\n",
        "initial_epochs = 5\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5F1ZZ8lVuAU"
      },
      "source": [
        "# heatmap validation after retraining\n",
        "\n",
        "downsize_factor = 1 # >=1\n",
        "\n",
        "for imagename in image_names_mask:\n",
        "  heatmap = gradCAM(image_dir_mask+'/'+imagename, model, model_string, target_input_dimension, heatmap_dimension, 'tf.identity',class_names)\n",
        "  heatmap = cv2.resize(heatmap, (int(heatmap.shape[1]/downsize_factor), int(heatmap.shape[0]/downsize_factor)))\n",
        "  cv2_imshow(heatmap)\n",
        "\n",
        "for imagename in image_names_no_maks:\n",
        "  heatmap = gradCAM(image_dir_no_maks+'/'+imagename, model, model_string, target_input_dimension, heatmap_dimension, 'tf.identity', class_names)\n",
        "  heatmap = cv2.resize(heatmap, (int(heatmap.shape[1]/downsize_factor), int(heatmap.shape[0]/downsize_factor)))\n",
        "  cv2_imshow(heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhRt1PIgv2tZ"
      },
      "source": [
        "# plot history of training and evaluate with test dataset\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a8RFmePzVlT"
      },
      "source": [
        "# apply other images\n",
        "\n",
        "downsize_factor = 2 # >1\n",
        "\n",
        "for imagename in image_names_mask2:\n",
        "  heatmap = gradCAM(other_path+image_dir_mask2+'/'+imagename, model, model_string, target_input_dimension, heatmap_dimension, 'tf.identity',class_names)\n",
        "  heatmap = cv2.resize(heatmap, (int(heatmap.shape[1]/downsize_factor), int(heatmap.shape[0]/downsize_factor)))\n",
        "  cv2_imshow(heatmap)\n",
        "\n",
        "for imagename in image_names_no_maks2:\n",
        "  heatmap = gradCAM(other_path+image_dir_no_maks2+'/'+imagename, model, model_string, target_input_dimension, heatmap_dimension, 'tf.identity', class_names)\n",
        "  heatmap = cv2.resize(heatmap, (int(heatmap.shape[1]/downsize_factor), int(heatmap.shape[0]/downsize_factor)))\n",
        "  cv2_imshow(heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_JSYShzs2dk"
      },
      "source": [
        "# retrain including convolutional layers\n",
        "\n",
        "model.layers[3].trainable = True\n",
        "\n",
        "initial_epochs = 20\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma4-w7rBzcX3"
      },
      "source": [
        "# heatmap validation after retraining\n",
        "\n",
        "downsize_factor = 1 # >=1\n",
        "\n",
        "for imagename in image_names_mask:\n",
        "  heatmap = gradCAM(image_dir_mask+'/'+imagename, model, model_string, target_input_dimension, heatmap_dimension, 'tf.identity',class_names)\n",
        "  heatmap = cv2.resize(heatmap, (int(heatmap.shape[1]/downsize_factor), int(heatmap.shape[0]/downsize_factor)))\n",
        "  cv2_imshow(heatmap)\n",
        "\n",
        "for imagename in image_names_no_maks:\n",
        "  heatmap = gradCAM(image_dir_no_maks+'/'+imagename, model, model_string, target_input_dimension, heatmap_dimension, 'tf.identity', class_names)\n",
        "  heatmap = cv2.resize(heatmap, (int(heatmap.shape[1]/downsize_factor), int(heatmap.shape[0]/downsize_factor)))\n",
        "  cv2_imshow(heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3Yozeo_ziyP"
      },
      "source": [
        "# plot history of training and evaluate with test dataset\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHjFKXwyzqzb"
      },
      "source": [
        "# apply other images\n",
        "\n",
        "downsize_factor = 2 # >1\n",
        "\n",
        "for imagename in image_names_mask2:\n",
        "  heatmap = gradCAM(other_path+image_dir_mask2+'/'+imagename, model, model_string, target_input_dimension, heatmap_dimension, 'tf.identity',class_names)\n",
        "  heatmap = cv2.resize(heatmap, (int(heatmap.shape[1]/downsize_factor), int(heatmap.shape[0]/downsize_factor)))\n",
        "  cv2_imshow(heatmap)\n",
        "\n",
        "for imagename in image_names_no_maks2:\n",
        "  heatmap = gradCAM(other_path+image_dir_no_maks2+'/'+imagename, model, model_string, target_input_dimension, heatmap_dimension, 'tf.identity', class_names)\n",
        "  heatmap = cv2.resize(heatmap, (int(heatmap.shape[1]/downsize_factor), int(heatmap.shape[0]/downsize_factor)))\n",
        "  cv2_imshow(heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDiks4v_q86z"
      },
      "source": [
        "## Archive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gguf9Vqpr6_x"
      },
      "source": [
        "### Observe Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfG1DR5gsCJk"
      },
      "source": [
        "# test augmentation 1\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.5),\n",
        "])\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "  plt.imshow(images[0].numpy().astype(\"uint8\"))\n",
        "  plt.title(class_names[labels[0]])\n",
        "  plt.axis(\"off\")\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i in range(9):\n",
        "    raw_image = np.expand_dims(images[0].numpy().astype(\"uint8\"), axis=0)\n",
        "    augmented_image = data_augmentation(raw_image)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_image[0])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIQ_vmHGrFHy"
      },
      "source": [
        "### from zip to files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0Fksoczq32q"
      },
      "source": [
        "import zipfile\n",
        "all_files=['/content/gdrive/My Drive/What are CNNs looking at/files/12k Face Mask Dataset/archive.zip']\n",
        "#all_files=['face-mask-detection.zip', 'face-mask-12k-images-dataset.zip', 'covid-face-mask-detection-dataset.zip']\n",
        "for file in all_files:\n",
        "  zip_ref = zipfile.ZipFile(file, 'r')\n",
        "  zip_ref.extractall('/content/gdrive/My Drive/What are CNNs looking at/files/12k Face Mask Dataset/')\n",
        "  zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmO-NprdrJtE"
      },
      "source": [
        "### separate labeled/unlabeled images from 'Face Mask Detection Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMf-SMolq6fZ"
      },
      "source": [
        "# separate images\n",
        "# to be run only once - already run -> finished\n",
        "\n",
        "import shutil\n",
        "\n",
        "path_to_dataset = \"/content/gdrive/MyDrive/What are CNNs looking at/files/Face Mask Detection Dataset/Medical mask/Medical mask/Medical Mask/images\"\n",
        "\n",
        "dirlist = os.listdir(path_to_dataset)\n",
        "image_list = []\n",
        "print(path_to_dataset)\n",
        "print(len(dirlist))\n",
        "i=0\n",
        "for f in dirlist:\n",
        "  sourcename = path_to_dataset+\"/\"+f\n",
        "  targetname = \"/content/gdrive/MyDrive/What are CNNs looking at/files/Multi Face Masks per Image clean/images/\"+f\n",
        "  print(i)\n",
        "  if os.path.isfile(os.path.join(path_to_dataset, \"../annotations/\", f+\".json\")):\n",
        "    image_list.append(f)\n",
        "    shutil.copyfile(sourcename, targetname)\n",
        "  i = i+1\n",
        "print(len(image_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-EA4aFtppb9"
      },
      "source": [
        "### import from csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNTvDapSpr1K"
      },
      "source": [
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml8oHPv6rBuX"
      },
      "source": [
        "# watch images from list_ds\n",
        "for f in list_ds.take(5):\n",
        "  img = cv2.imread(f.numpy().decode(\"utf-8\"))\n",
        "  img = cv2.resize(img, (int(img.shape[1]/2), int(img.shape[0]/2)))\n",
        "  cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vU26L2GrTYa"
      },
      "source": [
        "def translate_label(old_label):\n",
        "  mask_labels = [\"mask_colorful\", \"mask_surgical\"]\n",
        "  no_mask_labels = [\"turban\", \"helmet\", \"sunglasses\", \"eyeglasses\", \"hair_net\", \"hat\", \"goggles\", \"hood\"]\n",
        "  other_covering_label = [\"hijab_niqab\", \"scarf_bandana\", \"balaclava_ski_mask\", \"face_shield\", \"gas_mask\"]\n",
        "  if old_label in mask_labels:\n",
        "    new_label = \"face_with_mask\"\n",
        "  elif old_label in no_mask_labels:\n",
        "    new_label = \"face_no_mask\"\n",
        "  elif old_label in other_covering_label:\n",
        "    new_label = \"face_other_covering\"\n",
        "  return new_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AMFmIV0reqS"
      },
      "source": [
        "# import database with labels from csv\n",
        "\n",
        "if path_to_dataset != '/content/gdrive/My Drive/What are CNNs looking at/files/Multi Face Masks per Image clean/images':\n",
        "  print('This cell is not designed for the selected data base')\n",
        "  raise StopExecution\n",
        "\n",
        "label_file_name = \"/content/gdrive/MyDrive/What are CNNs looking at/files/Multi Face Masks per Image clean/train.csv\"\n",
        "valid_classes = [\"face_no_mask\", \"face_with_mask_incorrect\", \"face_with_mask\", \"face_other_covering\"]\n",
        "filelist = os.listdir(path_to_dataset)\n",
        "no_of_images = len(filelist)\n",
        "unique_filenames = [-1] * no_of_images\n",
        "labels_string = [\"\" for i in range(no_of_images)]\n",
        "\n",
        "with open(label_file_name, newline='') as csvfile:\n",
        "     reader = csv.DictReader(csvfile)\n",
        "     for row in reader:\n",
        "         if row['name'] not in unique_filenames and row['classname'] in valid_classes:\n",
        "             pos = filelist.index(row['name'])\n",
        "             unique_filenames[pos] = row['name']\n",
        "             labels_string[pos] = row['classname']\n",
        "        \n",
        "with open(label_file_name, newline='') as csvfile:\n",
        "     reader = csv.DictReader(csvfile)\n",
        "     for row in reader:\n",
        "         if row['name'] not in unique_filenames:\n",
        "             label = translate_label(row['classname'])\n",
        "             pos = filelist.index(row['name'])\n",
        "             unique_filenames[pos] = row['name']\n",
        "             labels_string[pos] = label\n",
        "\n",
        "# labels from string to int\n",
        "labels_int = []\n",
        "for label in labels_string:\n",
        "  labels_int.append(valid_classes.index(label))\n",
        "  if label == \"\":\n",
        "    print(\"Error! Empty label found: \")\n",
        "\n",
        "full_dataset = image_dataset_from_directory('/content/gdrive/My Drive/What are CNNs looking at/files/Multi Face Masks per Image clean/images', labels=labels_int, label_mode='int')\n",
        "\n",
        "print(full_dataset.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTNDu4aYrpTJ"
      },
      "source": [
        "### Other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvn-_Yqyrq-J"
      },
      "source": [
        "# temp\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "for images, labels in train_dataset.take(1):\n",
        "  i = 31\n",
        "  plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "  plt.title(class_names[labels[i]])\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for k in range(9):\n",
        "    augmented_image = data_augmentation(images[i])\n",
        "    ax = plt.subplot(3, 3, k + 1)\n",
        "    plt.imshow(augmented_image[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTYab420rw4Z"
      },
      "source": [
        "# temp\n",
        "for images, labels in train_dataset.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGxitxjCssEl"
      },
      "source": [
        "# access layers\n",
        "\n",
        "# access resnet layers\n",
        "#model.layers[3].layers\n",
        "#model.layers[3].get_layer(\"conv5_block3_3_conv\")\n",
        "#model.get_layer(\"resnet50\").get_layer(\"conv5_block3_3_conv\")\n",
        "\n",
        "#model.trainable\n",
        "#model.layers[3].trainable"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}